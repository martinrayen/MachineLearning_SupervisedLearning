{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective : To apply Text pre-processing on Amazon food reviews dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Reviews Analysis\n",
    "\n",
    "\n",
    "Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
    "\n",
    "Number of reviews: 568,454<br>\n",
    "Number of users: 256,059<br>\n",
    "Number of products: 74,258<br>\n",
    "Timespan: Oct 1999 - Oct 2012<br>\n",
    "Number of Attributes/Columns in data: 10 \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1.  Id\n",
    "2.  ProductId - unique identifier for the product\n",
    "3.  UserId - unqiue identifier for the user\n",
    "4.  ProfileName\n",
    "5.  HelpfulnessNumerator - number of users who found the review helpful\n",
    "6.  HelpfulnessDenominator - number of users who indicated whether they \n",
    "    found the review helpful or not\n",
    "7.  Score - rating between 1 and 5\n",
    "8.  Time - timestamp for the review\n",
    "9.  Summary - brief summary of the review\n",
    "10. Text - text of the review\n",
    "\n",
    "\n",
    "#### Objective:\n",
    "Given a review, determine whether the review is positive (Rating of 4 or 5) or negative (rating of 1 or 2).\n",
    "\n",
    "<br>\n",
    "[Q] How to determine if a review is positive or negative?<br>\n",
    "<br> \n",
    "[Ans] We could use the Score/Rating. A rating of 4 or 5 could be cosnidered a positive review.\n",
    "A review of 1 or 2 could be considered negative. A review of 3 is neutral and ignored. \n",
    "This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Amazon Reviews Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install tqdm\n",
    "\n",
    "from tqdm import tqdm # for displaying progress bar.\n",
    "\n",
    "\n",
    "# using the SQLite Table to read the amazon fine food reviews data.\n",
    "con = sqlite3.connect('database.sqlite') \n",
    "\n",
    "#filtering only positive and negative reviews i.e. \n",
    "# not taking into consideration those reviews with Score=3\n",
    "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 \"\"\", con) \n",
    "\n",
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning : Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    307061\n",
       "negative     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display= pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND UserId=\"AR5J8UI46CURR\"\n",
    "ORDER BY ProductID\n",
    "\"\"\", con)\n",
    "\n",
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "#Deduplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape\n",
    "\n",
    "#Remove Data anamolies.\n",
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "\n",
    "#Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed high FalsePositive cases during NB assignment.\n",
    "# Solution : Add the summary comments from the Amazon food reviews dataset to the review text column \n",
    "#            to reduce the FalsePositive counts.\n",
    "\n",
    "# Compare Model performance between using Review comments alone versus using Review comments + \n",
    "# Summary comments.\n",
    "#final['SummaryText'] = final['Text']\n",
    "final['SummaryText'] = ''\n",
    "final['SummaryText'] = final['Text'] + \". \" + final['Summary'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Text Preprocessing: Stemming, stop-word removal and Lemmatization.\n",
    "\n",
    "Now that we have finished deduplication our data requires some preprocessing \n",
    "before we go on further with analysis and making the prediction model.\n",
    "\n",
    "Hence in the Preprocessing phase we do the following in the order below:-\n",
    "\n",
    "1. Begin by removing the html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric\n",
    "4. Check to see if the length of the word is greater than 2 \n",
    "   (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase\n",
    "6. Remove Stopwords\n",
    "7. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)<br>\n",
    "\n",
    "After which we collect the words used to describe positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Vijay\n",
      "[nltk_data]     Joseph\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 364171/364171 [06:16<00:00, 966.67it/s]\n"
     ]
    }
   ],
   "source": [
    "#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n",
    "\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "# Take one review at a time.\n",
    "for sent in tqdm(final['SummaryText'].values):\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    # Split sentences into words.\n",
    "    for w in sent.split():\n",
    "        # Remove punctuations and special characters in each word.\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            # If the word is not a number and not english articles like a,an,...\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):\n",
    "                # If the word is not a stopword\n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    # Apply stemming on each word\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    # Append to list\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(final['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SummaryText</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>witti littl book make son laugh loud recit car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138688</th>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "      <td>grew read sendak book watch realli rosi movi i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138689</th>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "      <td>fun way children learn month year learn poem t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138690</th>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "      <td>great littl book read nice rhythm well good re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138691</th>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "      <td>book poetri month year goe month cute littl po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SummaryText  \\\n",
       "138706  this witty little book makes my son laugh at l...   \n",
       "138688  I grew up reading these Sendak books, and watc...   \n",
       "138689  This is a fun way for children to learn their ...   \n",
       "138690  This is a great little book to read aloud- it ...   \n",
       "138691  This is a book of poetry about the months of t...   \n",
       "\n",
       "                                              CleanedText  \n",
       "138706  witti littl book make son laugh loud recit car...  \n",
       "138688  grew read sendak book watch realli rosi movi i...  \n",
       "138689  fun way children learn month year learn poem t...  \n",
       "138690  great littl book read nice rhythm well good re...  \n",
       "138691  book poetri month year goe month cute littl po...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a column \"CleanedText\" to the final cleaned dataset that displays the data after \n",
    "# pre-processing of the review. \n",
    "final['CleanedText']=final_string \n",
    "final['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")\n",
    "final[['SummaryText','CleanedText']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the final cleaned text to csv file for resuse later.\n",
    "final.to_csv('finalCleanedText.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
